{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f63df4",
   "metadata": {},
   "source": [
    "# Global Energy Grid Stress & Resilience Prediction\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "- Data preparation & checks\n",
    "- Extensive EDA (ranges, missing values, target analysis)\n",
    "- Feature importance analysis\n",
    "- Model selection (linear + tree-based)\n",
    "- Hyperparameter tuning and final model selection\n",
    "\n",
    "**Target:** `grid_stress` (0 = normal, 1 = high stress)\n",
    "\n",
    "The dataset is built from OPSD Time Series data using `src/download_data.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "DATA_PATH = \"../data/processed/energy_grid_daily.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7888daf",
   "metadata": {},
   "source": [
    "## Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1301be",
   "metadata": {},
   "source": [
    "## Target variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = df[\"grid_stress\"].value_counts().to_frame(\"count\")\n",
    "target_dist[\"share\"] = target_dist[\"count\"] / target_dist[\"count\"].sum()\n",
    "target_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.bar([\"0 (normal)\", \"1 (stress)\"], df[\"grid_stress\"].value_counts().sort_index().values)\n",
    "plt.title(\"Target distribution\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49885915",
   "metadata": {},
   "source": [
    "## Feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c in df.columns if c not in [\"country\", \"grid_stress\"]]\n",
    "df[num_cols].hist(bins=30, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e47829",
   "metadata": {},
   "source": [
    "## Country coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"country\"].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400773d6",
   "metadata": {},
   "source": [
    "## Relationships and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ff7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[num_cols + [\"grid_stress\"]].corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr, aspect=\"auto\")\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd9a49",
   "metadata": {},
   "source": [
    "## Feature importance (tree-based baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = df.drop(columns=[\"grid_stress\"])\n",
    "y = df[\"grid_stress\"].astype(int)\n",
    "\n",
    "cat_cols = [\"country\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"num\", \"passthrough\", num_cols),\n",
    "])\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", rf),\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Extract feature names after one-hot encoding\n",
    "ohe = pipe.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "ohe_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "feature_names = ohe_names + num_cols\n",
    "\n",
    "importances = pipe.named_steps[\"model\"].feature_importances_\n",
    "imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "imp.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "imp.head(15).sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Top 15 feature importances (Random Forest)\")\n",
    "plt.xlabel(\"importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f95c6",
   "metadata": {},
   "source": [
    "## Model selection and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b362ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 1) Logistic Regression baseline\n",
    "logreg = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42)),\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "auc_log = roc_auc_score(y_val, logreg.predict_proba(X_val)[:, 1])\n",
    "auc_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a93a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Random Forest tuned\n",
    "rf_pipe = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "])\n",
    "\n",
    "rf_params = {\n",
    "    \"model__max_depth\": [3, 5, 8, 12, None],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None],\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_pipe,\n",
    "    rf_params,\n",
    "    n_iter=15,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_best = rf_search.best_estimator_\n",
    "auc_rf = roc_auc_score(y_val, rf_best.predict_proba(X_val)[:, 1])\n",
    "\n",
    "auc_rf, rf_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) XGBoost tuned\n",
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "scale_pos_weight = float(neg / max(pos, 1))\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "])\n",
    "\n",
    "xgb_params = {\n",
    "    \"model__max_depth\": [3, 4, 5, 6],\n",
    "    \"model__learning_rate\": [0.02, 0.05, 0.1],\n",
    "    \"model__subsample\": [0.7, 0.85, 1.0],\n",
    "    \"model__colsample_bytree\": [0.7, 0.85, 1.0],\n",
    "    \"model__min_child_weight\": [1, 3, 5],\n",
    "    \"model__reg_lambda\": [0.0, 1.0, 5.0],\n",
    "    \"model__scale_pos_weight\": [scale_pos_weight],\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    xgb_pipe,\n",
    "    xgb_params,\n",
    "    n_iter=18,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "auc_xgb = roc_auc_score(y_val, xgb_best.predict_proba(X_val)[:, 1])\n",
    "\n",
    "auc_xgb, xgb_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c368ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    {\"model\": \"logreg\", \"roc_auc\": auc_log},\n",
    "    {\"model\": \"rf_tuned\", \"roc_auc\": auc_rf},\n",
    "    {\"model\": \"xgb_tuned\", \"roc_auc\": auc_xgb},\n",
    "]).sort_values(\"roc_auc\", ascending=False)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4876ff1",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- The dataset shows clear differences between normal vs stress days in demand peak ratio and capacity margin proxy.\n",
    "- Tree-based models outperform the linear baseline in most configurations.\n",
    "- Hyperparameter tuning improves ROC-AUC and provides a transparent selection process.\n",
    "- The final training and model export for production are implemented in `src/train.py`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
